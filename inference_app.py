import os
import torch
import torch.nn as nn
from torchvision import models, datasets, transforms

from tkinter import (
    Tk, Frame, Label, Button, filedialog, messagebox, BOTH, LEFT, RIGHT, TOP, BOTTOM, X
)
from PIL import Image, ImageTk

import numpy as np
import matplotlib.pyplot as plt

from gradcam_utils import GradCAM, load_image_as_tensor, overlay_cam_on_image

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_PATH = "models/densenet121_pneumonia.pth"
DATA_DIR = "data/chest_xray"          # ÐºÐ¾Ñ€ÐµÐ½ÑŒ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° Kaggle
TEST_DIR = os.path.join(DATA_DIR, "test")


def load_model(model_path):
    checkpoint = torch.load(model_path, map_location=DEVICE)

    classes = checkpoint["classes"]

    model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)
    num_features = model.classifier.in_features
    model.classifier = nn.Linear(num_features, len(classes))
    model.load_state_dict(checkpoint["model_state_dict"], strict=False)
    model = model.to(DEVICE)
    model.eval()

    return model, classes


def predict_image(model, img_tensor):
    img_tensor = img_tensor.to(DEVICE)
    with torch.no_grad():
        outputs = model(img_tensor)
        probs = torch.softmax(outputs, dim=1)
        conf, pred = torch.max(probs, 1)

    return pred.item(), conf.item(), probs.cpu().numpy()[0]


class PneumoniaApp(Tk):
    def __init__(self):
        super().__init__()

        # --- Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¾ÐºÐ½Ð° ---
        self.title("Pneumonia Detection - DenseNet121 + Grad-CAM")
        self.geometry("1100x700")
        self.configure(bg="#1e1e1e")  # Ñ‚Ñ‘Ð¼Ð½Ñ‹Ð¹ Ñ„Ð¾Ð½

        # Ð¼Ð¾Ð´ÐµÐ»Ð¸
        if not os.path.exists(MODEL_PATH):
            messagebox.showerror(
                "ÐžÑˆÐ¸Ð±ÐºÐ°",
                f"Ð¤Ð°Ð¹Ð» Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {MODEL_PATH}\nÐ¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸ train_densenet.py."
            )
            self.destroy()
            return

        self.model, self.classes = load_model(MODEL_PATH)
        self.gradcam = GradCAM(self.model)

        # Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
        self.image_path = None
        self.original_pil = None
        self.original_tk = None
        self.gradcam_tk = None

        # Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ test-Ð½Ð°Ð±Ð¾Ñ€Ð° (Ð´Ð»Ñ confusion matrix)
        self.test_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406],
                                 [0.229, 0.224, 0.225])
        ])

        # --- layout ---
        self._build_layout()

    def _build_layout(self):
        # Ð²ÐµÑ€Ñ…Ð½ÑÑ Ð¿Ð°Ð½ÐµÐ»ÑŒ Ñ ÐºÐ½Ð¾Ð¿ÐºÐ°Ð¼Ð¸
        top_frame = Frame(self, bg="#252526")
        top_frame.pack(side=TOP, fill=X, padx=10, pady=10)

        btn_load = Button(
            top_frame,
            text="ðŸ“‚ Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ ÑÐ½Ð¸Ð¼Ð¾Ðº",
            command=self.load_image,
            bg="#0e639c",
            fg="white",
            activebackground="#1177bb",
            relief="flat",
            padx=15,
            pady=6
        )
        btn_load.pack(side=LEFT, padx=5)

        self.btn_predict = Button(
            top_frame,
            text="ðŸ©º ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ñ‚ÑŒ",
            command=self.run_prediction,
            bg="#3c873a",
            fg="white",
            activebackground="#46a049",
            relief="flat",
            padx=15,
            pady=6,
            state="disabled"
        )
        self.btn_predict.pack(side=LEFT, padx=5)

        btn_cm = Button(
            top_frame,
            text="ðŸ“Š Confusion Matrix (test)",
            command=self.show_confusion_matrix,
            bg="#6439b7",
            fg="white",
            activebackground="#7d4ede",
            relief="flat",
            padx=15,
            pady=6,
        )
        btn_cm.pack(side=LEFT, padx=5)

        # Ñ†ÐµÐ½Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ: Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
        center_frame = Frame(self, bg="#1e1e1e")
        center_frame.pack(side=TOP, fill=BOTH, expand=True, padx=10, pady=(0, 10))

        # Ð»ÐµÐ²Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»)
        left_img_frame = Frame(center_frame, bg="#1e1e1e")
        left_img_frame.pack(side=LEFT, fill=BOTH, expand=True, padx=5)

        Label(
            left_img_frame,
            text="ÐžÑ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐ½Ð¸Ð¼Ð¾Ðº",
            bg="#1e1e1e",
            fg="white",
            font=("Helvetica", 12, "bold")
        ).pack(side=TOP, pady=5)

        self.original_label = Label(left_img_frame, bg="#252526")
        self.original_label.pack(side=TOP, fill=BOTH, expand=True, padx=5, pady=5)

        # Ð¿Ñ€Ð°Ð²Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (Grad-CAM)
        right_img_frame = Frame(center_frame, bg="#1e1e1e")
        right_img_frame.pack(side=RIGHT, fill=BOTH, expand=True, padx=5)

        Label(
            right_img_frame,
            text="Grad-CAM Heatmap",
            bg="#1e1e1e",
            fg="white",
            font=("Helvetica", 12, "bold")
        ).pack(side=TOP, pady=5)

        self.gradcam_label = Label(right_img_frame, bg="#252526")
        self.gradcam_label.pack(side=TOP, fill=BOTH, expand=True, padx=5, pady=5)

        # Ð½Ð¸Ð¶Ð½ÑÑ Ð¿Ð°Ð½ÐµÐ»ÑŒ Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼Ð¸
        bottom_frame = Frame(self, bg="#252526")
        bottom_frame.pack(side=BOTTOM, fill=X, padx=10, pady=10)

        self.pred_label = Label(
            bottom_frame,
            text="ÐšÐ»Ð°ÑÑ: â€”",
            bg="#252526",
            fg="white",
            font=("Helvetica", 14, "bold")
        )
        self.pred_label.pack(side=TOP, anchor="w", pady=2)

        self.conf_label = Label(
            bottom_frame,
            text="Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: â€”",
            bg="#252526",
            fg="white",
            font=("Helvetica", 12)
        )
        self.conf_label.pack(side=TOP, anchor="w", pady=2)

        self.prob_label = Label(
            bottom_frame,
            text="Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾ ÐºÐ»Ð°ÑÑÐ°Ð¼: â€”",
            bg="#252526",
            fg="white",
            font=("Helvetica", 12),
            justify="left"
        )
        self.prob_label.pack(side=TOP, anchor="w", pady=2)

    # ---------- Ñ€Ð°Ð±Ð¾Ñ‚Ð° Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸ ----------

    def _resize_for_display(self, pil_img, max_size=(500, 500)):
        img = pil_img.copy()
        img.thumbnail(max_size, Image.Resampling.LANCZOS)
        return img

    def load_image(self):
        path = filedialog.askopenfilename(
            title="Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ€ÐµÐ½Ñ‚Ð³ÐµÐ½-ÑÐ½Ð¸Ð¼Ð¾Ðº Ð»Ñ‘Ð³ÐºÐ¸Ñ…",
            filetypes=[("Image files", "*.png *.jpg *.jpeg")]
        )
        if not path:
            return

        try:
            pil_img = Image.open(path).convert("RGB")
        except Exception as e:
            messagebox.showerror("ÐžÑˆÐ¸Ð±ÐºÐ°", f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚ÑŒ Ñ„Ð°Ð¹Ð»:\n{e}")
            return

        self.image_path = path
        self.original_pil = pil_img

        # Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶Ð°ÐµÐ¼ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»
        disp_img = self._resize_for_display(pil_img)
        self.original_tk = ImageTk.PhotoImage(disp_img)
        self.original_label.configure(image=self.original_tk)

        # Ð¾Ñ‡Ð¸Ñ‰Ð°ÐµÐ¼ Grad-CAM Ð¸ Ñ‚ÐµÐºÑÑ‚
        self.gradcam_label.configure(image="")
        self.gradcam_tk = None
        self.pred_label.configure(text="ÐšÐ»Ð°ÑÑ: â€”", fg="white")
        self.conf_label.configure(text="Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: â€”")
        self.prob_label.configure(text="Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾ ÐºÐ»Ð°ÑÑÐ°Ð¼: â€”")

        # Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ ÐºÐ½Ð¾Ð¿ÐºÑƒ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ
        self.btn_predict.configure(state="normal")

    def run_prediction(self):
        if self.image_path is None:
            messagebox.showwarning("Ð’Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ", "Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ ÑÐ½Ð¸Ð¼Ð¾Ðº.")
            return

        pil_img, img_tensor = load_image_as_tensor(self.image_path)

        pred_idx, conf, probs = predict_image(self.model, img_tensor)
        pred_class = self.classes[pred_idx]
        conf_percent = conf * 100

        # Ñ†Ð²ÐµÑ‚ Ñ‚ÐµÐºÑÑ‚Ð° Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ð´Ð¸Ð°Ð³Ð½Ð¾Ð·Ð°
        if pred_class.lower() == "pneumonia":
            color = "#ff5555"  # ÐºÑ€Ð°ÑÐ½Ñ‹Ð¹
        else:
            color = "#4ec9b0"  # Ð·ÐµÐ»Ñ‘Ð½Ñ‹Ð¹

        self.pred_label.configure(text=f"ÐšÐ»Ð°ÑÑ: {pred_class}", fg=color)
        self.conf_label.configure(text=f"Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {conf_percent:.2f}%")

        probs_text_lines = []
        for cl, p in zip(self.classes, probs):
            probs_text_lines.append(f"  {cl}: {p * 100:.2f}%")
        probs_text = "Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾ ÐºÐ»Ð°ÑÑÐ°Ð¼:\n" + "\n".join(probs_text_lines)

        self.prob_label.configure(text=probs_text)

        # --- Grad-CAM ---
        cam = self.gradcam.generate(img_tensor, target_class=pred_idx)
        overlay_np = overlay_cam_on_image(self.original_pil, cam)

        overlay_pil = Image.fromarray(overlay_np)
        overlay_disp = self._resize_for_display(overlay_pil)
        self.gradcam_tk = ImageTk.PhotoImage(overlay_disp)
        self.gradcam_label.configure(image=self.gradcam_tk)

    # ---------- Confusion Matrix ----------

    def show_confusion_matrix(self):
        if not os.path.isdir(TEST_DIR):
            messagebox.showerror(
                "ÐžÑˆÐ¸Ð±ÐºÐ°",
                f"ÐŸÐ°Ð¿ÐºÐ° Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°:\n{TEST_DIR}"
            )
            return

        # Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ test-Ð½Ð°Ð±Ð¾Ñ€
        test_dataset = datasets.ImageFolder(TEST_DIR, transform=self.test_transform)

        # Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ð¼, Ñ‡Ñ‚Ð¾ Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº ÐºÐ»Ð°ÑÑÐ¾Ð² ÑÐ¾Ð²Ð¿Ð°Ð´Ð°ÐµÑ‚
        if test_dataset.classes != list(self.classes):
            # ÐµÑÐ»Ð¸ Ñ…Ð¾Ñ‚ÑÑ‚, Ð¼Ð¾Ð¶Ð½Ð¾ Ð²Ñ‹Ð²ÐµÑÑ‚Ð¸ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ðµ
            print("Ð’Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ: Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº ÐºÐ»Ð°ÑÑÐ¾Ð² Ð² test-Ð½Ð°Ð±Ð¾Ñ€Ðµ Ð¸ Ð² Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð°ÐµÑ‚ÑÑ.")
            print("ÐœÐ¾Ð´ÐµÐ»ÑŒ:", self.classes)
            print("Test dataset:", test_dataset.classes)

        test_loader = torch.utils.data.DataLoader(
            test_dataset,
            batch_size=16,
            shuffle=False,
            num_workers=2
        )

        all_preds = []
        all_labels = []

        self.model.eval()
        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs = inputs.to(DEVICE)
                labels = labels.to(DEVICE)

                outputs = self.model(inputs)
                _, preds = torch.max(outputs, 1)

                all_preds.extend(preds.cpu().numpy().tolist())
                all_labels.extend(labels.cpu().numpy().tolist())

        num_classes = len(self.classes)
        cm = np.zeros((num_classes, num_classes), dtype=int)

        for t, p in zip(all_labels, all_preds):
            cm[t, p] += 1

        # Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ñ‹
        fig, ax = plt.subplots(figsize=(4, 4))
        im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
        ax.figure.colorbar(im, ax=ax)

        ax.set(
            xticks=np.arange(num_classes),
            yticks=np.arange(num_classes),
            xticklabels=self.classes,
            yticklabels=self.classes,
            ylabel='Ð˜ÑÑ‚Ð¸Ð½Ð½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ',
            xlabel='ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ',
            title='Confusion Matrix (Test set)'
        )

        # Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ¸ Ð² ÑÑ‡ÐµÐ¹ÐºÐ°Ñ…
        thresh = cm.max() / 2.0
        for i in range(num_classes):
            for j in range(num_classes):
                ax.text(
                    j, i, str(cm[i, j]),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black"
                )

        fig.tight_layout()
        plt.show()


def main():
    app = PneumoniaApp()
    app.mainloop()


if __name__ == "__main__":
    main()
